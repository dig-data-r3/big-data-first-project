{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relazione Finale\n",
    "**Gruppo - Dig Data**\n",
    "\n",
    "**Componenti Gruppo - Alexandru Pavel, Simone Garzarella**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indice\n",
    "- [Introduzione](#introduction)\n",
    "    - [Descrizione Problema](#problem-description)\n",
    "    - [Specifiche Software](#sw-specs)\n",
    "    - [Specifiche Software](#hw-specs)\n",
    "- [Analisi Dataset](#data-analysis)\n",
    "    - [Historical Stock Prices](#hsp)\n",
    "    - [Historical Stocks](#hs)\n",
    "- [Job 1](#job1)\n",
    "    - [MapReduce](#mapreduce1)\n",
    "    - [Hive](#hive1)\n",
    "    - [Spark](#spark1)\n",
    "- [Job 2](#job2)\n",
    "    - [MapReduce](#mapreduce2)\n",
    "    - [Hive](#hive2)\n",
    "    - [Spark](#spark2)\n",
    "- [Job 3](#job3)\n",
    "    - [MapReduce](#mapreduce3)\n",
    "    - [Hive](#hive3)\n",
    "    - [Spark](#spark3)\n",
    "- [Risultati](#results)\n",
    "    - [Job 1](#plot1)\n",
    "    - [Job 2](#plot2)\n",
    "    - [Job 3](#plot3)\n",
    "- [Conclusioni](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzione <a name=\"introduction\"></a>\n",
    "Il dataset \"Daily Historical Stock Prices\" contiene l'andamento delle azioni sulla borsa di New York (NYSE e NASDAQ) dal 1970 al 2018. \n",
    "\n",
    "Due file CSV compongono il dataset:\n",
    "- historical_stock_prices.csv\n",
    "- historical_stocks.csv\n",
    "\n",
    "Il primo contiene i valori dei prezzi e volumi che variano nel tempo per ogni ticker. Il secondo i dati relativi ad ogni ticker, come il settore e l'exchange in cui è quotato.\n",
    "\n",
    "## Descrizione Problema <a name=\"problem-description\"></a>\n",
    "Dopo una fase iniziale di analisi e processamento di dati si vogliono eseguire 3 job (descritti nel dettaglio più avanti) con le diverse tecnologie affrontate nel corso (Hadoop, Hive e Apache Spark).\n",
    "\n",
    "## Specifiche Software <a name=\"sw-specs\"></a>\n",
    "Serve? Python, Hadoop, Hive, Spark con versioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifiche Hardware <a name=\"hw-specs\"></a>\n",
    "I test sono stati eseguiti in locale e su cluster con macchine con queste caratteristiche:\n",
    "- **Locale:** Ubuntu 20.04, CPU i5 2.5GHZ, 8GB Ram e 256GB SSD\n",
    "- **Cluster:** AWS EMR con 1 Master Node e 5 DataNode. Istanze m5.xlarge con 16GB RAM, 4 vCPU e 50GB SSD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi Dataset <a name=\"data-analysis\"></a>\n",
    "\n",
    "Di seguito vengono analizzati i due file del dataset per individuare eventuali preprocessamenti da effettuare. Inoltre viene anche descritto il processo per creare dataset più piccoli o grandi (con sampling) per effettuare i successivi test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Stock Prices <a name=\"hsp\"></a>\n",
    "\n",
    "I campi di questo dataset sono:\n",
    "\n",
    "- `ticker`: simbolo univoco dell’azione (https://en.wikipedia.org/wiki/Ticker_symbol)\n",
    "- `open`: prezzo di apertura\n",
    "- `close`: prezzo di chiusura\n",
    "- `adj_close`: prezzo di chiusura “modificato”\n",
    "- `lowThe`: prezzo minimo\n",
    "- `highThe`: prezzo massimo\n",
    "- `volume`: numero di transazioni\n",
    "- `date`: data nel formato aaaa-mm-gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = pd.read_csv('dataset/historical_stock_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.58</td>\n",
       "      <td>8.493155</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.68</td>\n",
       "      <td>4633900</td>\n",
       "      <td>2013-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.66</td>\n",
       "      <td>11.55</td>\n",
       "      <td>8.471151</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.66</td>\n",
       "      <td>275800</td>\n",
       "      <td>2013-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.60</td>\n",
       "      <td>8.507822</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>277100</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.65</td>\n",
       "      <td>8.544494</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.65</td>\n",
       "      <td>147400</td>\n",
       "      <td>2013-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.53</td>\n",
       "      <td>8.456484</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>184100</td>\n",
       "      <td>2013-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973884</th>\n",
       "      <td>NZF</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.59</td>\n",
       "      <td>14.590000</td>\n",
       "      <td>14.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>137500</td>\n",
       "      <td>2018-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973885</th>\n",
       "      <td>NZF</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.58</td>\n",
       "      <td>14.580000</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.61</td>\n",
       "      <td>151200</td>\n",
       "      <td>2018-08-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973886</th>\n",
       "      <td>NZF</td>\n",
       "      <td>14.58</td>\n",
       "      <td>14.59</td>\n",
       "      <td>14.590000</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.63</td>\n",
       "      <td>185400</td>\n",
       "      <td>2018-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973887</th>\n",
       "      <td>NZF</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.570000</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.64</td>\n",
       "      <td>135600</td>\n",
       "      <td>2018-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973888</th>\n",
       "      <td>NZF</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.69</td>\n",
       "      <td>14.690000</td>\n",
       "      <td>14.59</td>\n",
       "      <td>14.69</td>\n",
       "      <td>180900</td>\n",
       "      <td>2018-08-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20973889 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker   open  close  adj_close    low   high   volume        date\n",
       "0           AHH  11.50  11.58   8.493155  11.25  11.68  4633900  2013-05-08\n",
       "1           AHH  11.66  11.55   8.471151  11.50  11.66   275800  2013-05-09\n",
       "2           AHH  11.55  11.60   8.507822  11.50  11.60   277100  2013-05-10\n",
       "3           AHH  11.63  11.65   8.544494  11.55  11.65   147400  2013-05-13\n",
       "4           AHH  11.60  11.53   8.456484  11.50  11.60   184100  2013-05-14\n",
       "...         ...    ...    ...        ...    ...    ...      ...         ...\n",
       "20973884    NZF  14.60  14.59  14.590000  14.58  14.62   137500  2018-08-20\n",
       "20973885    NZF  14.60  14.58  14.580000  14.57  14.61   151200  2018-08-21\n",
       "20973886    NZF  14.58  14.59  14.590000  14.57  14.63   185400  2018-08-22\n",
       "20973887    NZF  14.60  14.57  14.570000  14.57  14.64   135600  2018-08-23\n",
       "20973888    NZF  14.60  14.69  14.690000  14.59  14.69   180900  2018-08-24\n",
       "\n",
       "[20973889 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono ~21milioni di record per questo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker       0\n",
       "open         0\n",
       "close        0\n",
       "adj_close    0\n",
       "low          0\n",
       "high         0\n",
       "volume       0\n",
       "date         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non sono presenti valori nulli per nessuna delle colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker          5685\n",
       "open          807688\n",
       "close         835181\n",
       "adj_close    9235753\n",
       "low           815237\n",
       "high          821044\n",
       "volume        385849\n",
       "date           12274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In totale ci sono 5685 `ticker` univoci nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices[stock_prices.duplicated(subset=['ticker','date'])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non ci sono record distinti con valori duplicati di (ticker, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione di dataset di varie dimensioni\n",
    "\n",
    "Sono stati generati dataset di dimensioni (approssimativamente) di 256/512/1024MB e ~4GB, oltre al dataset originale che ha dimensioni ~2GB.\n",
    "\n",
    "I file generati (con relativa dimensione precisa) hanno nome historical_stock_prices[size].csv\n",
    "\n",
    "- historical_stock_prices`256`.csv &ensp;&ensp;(239.75MB)\n",
    "- historical_stock_prices`512`.csv &ensp;&ensp;(479.51MB)\n",
    "- historical_stock_prices`1024`.csv &ensp;(959.03MB)\n",
    "- historical_stock_prices.csv &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;(1909.97MB)\n",
    "- historical_stock_prices`4096`.csv &ensp;(3835.92MB)\n",
    "\n",
    "La scelta dei record da includere è effettuata con un sampling randomico (con un seed preimpostato, per la ripetibiltà)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def sample_all_sizes(historical_stock_prices_df):\n",
    "    for size in [0.125, 0.25, 0.5, 2]:\n",
    "        sample_n_rows = dataset_row_count * size\n",
    "        sampled_df = dataset.sample(sample_n_rows)\n",
    "        filename = 'dataset/historical_stock_prices[SIZE].csv')\n",
    "        sampled_df.to_csv(filename)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Stocks <a name=\"hs\"></a>\n",
    "\n",
    "Il dataset con le informazioni sui ticker è così strutturato:\n",
    "\n",
    "- `ticker`: simbolo dell’azione\n",
    "- `exchange`: NYSE o NASDAQ\n",
    "- `name`: nome dell’azienda\n",
    "- `sector`: settore dell’azienda\n",
    "- `industry`: industria di riferimento per l’azienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(\"dataset/historical_stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIHPP</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TURN</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>180 DEGREE CAPITAL CORP.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>FINANCE/INVESTORS SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLWS</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1-800 FLOWERS.COM, INC.</td>\n",
       "      <td>CONSUMER SERVICES</td>\n",
       "      <td>OTHER SPECIALTY STORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCCY</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1ST CONSTITUTION BANCORP (NJ)</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>SAVINGS INSTITUTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6455</th>\n",
       "      <td>ZOES</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>ZOE&amp;#39;S KITCHEN, INC.</td>\n",
       "      <td>CONSUMER SERVICES</td>\n",
       "      <td>RESTAURANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>ZOETIS INC.</td>\n",
       "      <td>HEALTH CARE</td>\n",
       "      <td>MAJOR PHARMACEUTICALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>ZTO</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>ZTO EXPRESS (CAYMAN) INC.</td>\n",
       "      <td>TRANSPORTATION</td>\n",
       "      <td>TRUCKING FREIGHT/COURIER SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>ZUORA, INC.</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>COMPUTER SOFTWARE: PREPACKAGED SOFTWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>ZYMEWORKS INC.</td>\n",
       "      <td>HEALTH CARE</td>\n",
       "      <td>MAJOR PHARMACEUTICALS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6460 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker exchange                                    name  \\\n",
       "0       PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.   \n",
       "1     PIHPP   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.   \n",
       "2      TURN   NASDAQ                180 DEGREE CAPITAL CORP.   \n",
       "3      FLWS   NASDAQ                 1-800 FLOWERS.COM, INC.   \n",
       "4      FCCY   NASDAQ           1ST CONSTITUTION BANCORP (NJ)   \n",
       "...     ...      ...                                     ...   \n",
       "6455   ZOES     NYSE                 ZOE&#39;S KITCHEN, INC.   \n",
       "6456    ZTS     NYSE                             ZOETIS INC.   \n",
       "6457    ZTO     NYSE               ZTO EXPRESS (CAYMAN) INC.   \n",
       "6458    ZUO     NYSE                             ZUORA, INC.   \n",
       "6459   ZYME     NYSE                          ZYMEWORKS INC.   \n",
       "\n",
       "                 sector                                 industry  \n",
       "0               FINANCE               PROPERTY-CASUALTY INSURERS  \n",
       "1               FINANCE               PROPERTY-CASUALTY INSURERS  \n",
       "2               FINANCE               FINANCE/INVESTORS SERVICES  \n",
       "3     CONSUMER SERVICES                   OTHER SPECIALTY STORES  \n",
       "4               FINANCE                     SAVINGS INSTITUTIONS  \n",
       "...                 ...                                      ...  \n",
       "6455  CONSUMER SERVICES                              RESTAURANTS  \n",
       "6456        HEALTH CARE                    MAJOR PHARMACEUTICALS  \n",
       "6457     TRANSPORTATION        TRUCKING FREIGHT/COURIER SERVICES  \n",
       "6458         TECHNOLOGY  COMPUTER SOFTWARE: PREPACKAGED SOFTWARE  \n",
       "6459        HEALTH CARE                    MAJOR PHARMACEUTICALS  \n",
       "\n",
       "[6460 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker      6460\n",
       "exchange       2\n",
       "name        5462\n",
       "sector        13\n",
       "industry     136\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sono presenti 6460 `ticker` univoci, come il numero di righe del dataset. Il ticker può essere considerato una chiave di questo dataset, il nome dell'azienda `name` invece no, ha delle ripetizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks[stocks.duplicated(subset=['name'])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particolare sono presenti 998 nomi di azienda duplicati. Nel resto del progetto non si considererà questo campo per identificare record (in particolare per il job3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FINANCE', 'CONSUMER SERVICES', 'TECHNOLOGY', 'PUBLIC UTILITIES',\n",
       "       'CAPITAL GOODS', 'BASIC INDUSTRIES', 'HEALTH CARE',\n",
       "       'CONSUMER DURABLES', nan, 'ENERGY', 'MISCELLANEOUS', 'SECTOR',\n",
       "       'TRANSPORTATION', 'CONSUMER NON-DURABLES'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks['sector'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizzando i possibili valori di `sector` si può notare la presenza di un valore nullo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker         0\n",
       "exchange       0\n",
       "name           0\n",
       "sector      1440\n",
       "industry    1440\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il campo `sector` presenta 1440 valori nulli, che vengono eliminati durante il preprocessing di questo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean = stocks.loc[(stocks['sector'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5020, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset pulito dai valori nulli del campo `sector` ha 5020 record. Verrà salvato come `historical_stocks_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "stocks_clean.to_csv('dataset/historical_stocks_clean.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job 1 <a name=\"job1\"></a>\n",
    "\n",
    "Deve generare un report contenente, per ciascuna azione:\n",
    "\n",
    "- data prima quotazione\n",
    "- data ultima quotazione\n",
    "- variazione percentuale della quotazione (tra primo e ultimo prezzo di chiusura nel dataset)\n",
    "- prezzo massimo \n",
    "- prezzo minimo\n",
    "\n",
    "Il report deve essere ordinato per valori decrescenti del secondo punto (dalla data di quotazione più recente alla più vecchia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce <a name=\"mapreduce1\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class mapper:\n",
    "    \n",
    "    for row in INPUT:\n",
    "        # split the current row into fields (ignoring not needed ones)\n",
    "        ticker, closePrice, minPrice, maxPrice, date = row\n",
    "\n",
    "        # write the separated fields to standard output\n",
    "        print(ticker, closePrice, minPrice, maxPrice, date)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python    \n",
    "class reducer:\n",
    "    \n",
    "    # maps each ticker to the required values to calculate\n",
    "    # for example: {'AAPL': {'min': 1, 'max': 2, ..},\n",
    "    #               'AMZN': {'min': 0.5, 'max': 5, ..}}\n",
    "    results = {}\n",
    "\n",
    "    for row in INPUT:        \n",
    "        # split the current row into fields\n",
    "        ticker, closePrice, minPrice, maxPrice, date = row\n",
    "\n",
    "        # if the ticker hasn't been seen before, initialize its values in the dictionary\n",
    "        if ticker not in results:\n",
    "            results[ticker] = {\n",
    "                'first_quot_date': date,\n",
    "                'last_quot_date': date,\n",
    "                'first_quot_price': closePrice,\n",
    "                'last_quot_price': closePrice,\n",
    "                'perc_var': 0,\n",
    "                'min_price': minPrice,\n",
    "                'max_price': maxPrice\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # gets the input ticker's current saved values from the dictionary\n",
    "        currTicker = results[ticker]\n",
    "\n",
    "        # update the saved ticker values with the ones from the input data\n",
    "        if date < currTicker['first_quot_date']:\n",
    "            currTicker['first_quot_date'] = date\n",
    "            currTicker['first_quot_price'] = closePrice\n",
    "            \n",
    "        if date > currTicker['last_quot_date']:\n",
    "            currTicker['last_quot_date'] = date\n",
    "            currTicker['last_quot_price'] = closePrice\n",
    "            \n",
    "        if minPrice < currTicker['min_price']:\n",
    "            currTicker['min_price'] = minPrice\n",
    "            \n",
    "        if maxPrice > currTicker['max_price']:\n",
    "            currTicker['max_price'] = maxPrice\n",
    "\n",
    "    # sort the results from the most to the least recent quotation dates\n",
    "    sortedResults = sort(results.items(), key='last_quot_date', descending=True)\n",
    "\n",
    "    # result is in the format ('TickerName', {'min': 1, 'max': 2}), a tuple\n",
    "    for result in sortedResults:\n",
    "        perc_var = calculate_percent_variation(first_quot_price, last_quot_price)\n",
    "\n",
    "        print(ticker, first_quot_date, last_quot_date, perc_var, min_price, max_price)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive <a name=\"hive1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per eseguire questo job sono state create prima due tabelle esterne:\n",
    "\n",
    "* Una che, per ogni ticker, etrae il prezzo di chiusura alla prima data disponibile per quel ticker nel database:\n",
    "\n",
    "\n",
    "```SQL\n",
    " create table ticker_to_minDate as\n",
    " select d.ticker as min_ticker, d.close_price as min_close_price\n",
    " from historical_stock_prices(size) d\n",
    " join (select ticker as min_ticker, min(price_date) as min_price_date\n",
    " from historical_stock_prices(size) group by ticker) min_table\n",
    " on (d.ticker = min_table.min_ticker and d.price_date <= min_table.min_price_date);\n",
    "```\n",
    " \n",
    "* L'altra che, per ogni ticker, etrae il prezzo di chiusura allultima data disponibile per quel ticker nel database:\n",
    "\n",
    "```SQL\n",
    " create table ticker_to_maxDate as\n",
    " select d.ticker as max_ticker, d.close_price as max_close_price\n",
    " from historical_stock_prices(size) d\n",
    " join (select ticker as max_ticker, max(price_date) as max_price_date\n",
    " from historical_stock_prices(size) group by ticker) as max_table\n",
    " on (d.ticker = max_table.max_ticker and d.price_date >= max_table.max_price_date);\n",
    "```\n",
    "\n",
    "\n",
    "* Successivamente esse sono state utilizzate per la query finale, in cui si estrae, per ogni ticker, la data della prima quotazione, la data dell’ultima quotazione, la variazione percentuale della quotazione, il prezzo massimo e quello minimo.\n",
    "\n",
    "```SQL\n",
    " CREATE TABLE job1_hive ROW FORMAT DELIMITED\n",
    " FIELDS TERMINATED BY '\\t'\n",
    " LINES TERMINATED BY '\\n' as\n",
    " select ticker, min(price_date) as first_price_date, max(price_date) as last_price_date,\n",
    " max(((max_table.max_close_price - min_table.min_close_price) / min_table.min_close_price) * 100) as variation,\n",
    " max(high) as max_price, min(low) as min_price\n",
    " from historical_stock_prices(size) d\n",
    " join ticker_to_maxDate max_table on d.ticker = max_table.max_ticker\n",
    " join ticker_to_minDate min_table on d.ticker = min_table.min_ticker\n",
    " group by ticker\n",
    " order by ticker, last_price_date desc;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark <a name=\"spark1\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"spark application\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "# create parser and set its arguments\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def min_date(a, b):\n",
    "    date_a = datetime.strptime(a[1], '%Y-%m-%d').date()\n",
    "    date_b = datetime.strptime(b[1], '%Y-%m-%d').date()\n",
    "    if date_a <= date_b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "\n",
    "def max_date(a, b):\n",
    "    date_a = datetime.strptime(a[1], '%Y-%m-%d').date()\n",
    "    date_b = datetime.strptime(b[1], '%Y-%m-%d').date()\n",
    "    if date_a >= date_b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "\n",
    "def calculate_percent_variation(initial, final):\n",
    "    return (float(final) - float(initial)) / float(initial) * 100\n",
    "\n",
    "\n",
    "# fields index in a row (in historical_stock_prices.csv)\n",
    "TICKER = 0\n",
    "OPEN = 1\n",
    "CLOSE = 2\n",
    "ADJ_CLOSE = 3\n",
    "MIN = 4\n",
    "MAX = 5\n",
    "VOLUME = 6\n",
    "DATE = 7\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_path\", type=str, help=\"Input file path\")\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"Output folder path\")\n",
    "\n",
    "# parse arguments\n",
    "args = parser.parse_args()\n",
    "input_filepath, output_filepath = args.input_path, args.output_path\n",
    "\n",
    "# initialize SparkSession\n",
    "# with the proper configuration\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Job1 Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# spark.sparkContext.textFile(filepath) returns an RDD\n",
    "# with a record for each line in the input file\n",
    "historical_stock_prices = sc.textFile(input_filepath).cache()\n",
    "\n",
    "split_input = historical_stock_prices.map(lambda line: line.strip().split(','))\n",
    "# filter the header row\n",
    "remove_first_row = split_input.filter(lambda line: line[TICKER] != 'ticker')\n",
    "\n",
    "# new RDD with a key-value pair of ticker and (close, date). We need to save the close price together with the date\n",
    "ticker_date = remove_first_row.map(lambda line: (line[TICKER], (line[CLOSE], line[DATE])))\n",
    "first_quot_date = ticker_date.reduceByKey(lambda a, b: min_date(a, b))\n",
    "last_quot_date = ticker_date.reduceByKey(lambda a, b: max_date(a, b))\n",
    "\n",
    "# after the join we will have (ticker, ((first_close, first_date), (last_close, last_date)))\n",
    "# we want to flatten as (ticker, (first_close, first_date, last_close, last_date))\n",
    "join_first_last_date = first_quot_date.join(last_quot_date) \\\n",
    "    .map(lambda x: (x[0], (x[1][0] + x[1][1])))\n",
    "\n",
    "# then calculate che percent variation and obtain (ticker, (first_date, last_date, perc_var))\n",
    "percent_variation = join_first_last_date.map(lambda x: (x[0],  # ticker\n",
    "                                                        (x[1][1],  # first_date\n",
    "                                                         x[1][3],  # last_date\n",
    "                                                         calculate_percent_variation(x[1][0], x[1][2]))))\n",
    "\n",
    "# (ticker, min_price) for each ticker\n",
    "min_price = remove_first_row.map(lambda line: (line[TICKER], line[MIN])) \\\n",
    "    .reduceByKey(lambda a, b: min(float(a), float(b)))\n",
    "# (ticker, max_price) for each ticker\n",
    "max_price = remove_first_row.map(lambda line: (line[TICKER], line[MAX])) \\\n",
    "    .reduceByKey(lambda a, b: max(float(a), float(b)))\n",
    "\n",
    "# join together all the calculated results, in the form (ticker, (first_date, last_date, percent_var, min, max))\n",
    "# also it has to be ordered by last_date descending\n",
    "results = percent_variation.join(min_price) \\\n",
    "    .map(lambda x: (x[0], (x[1][0] + (x[1][1],)))) \\\n",
    "    .join(max_price) \\\n",
    "    .map(lambda x: (x[0], (x[1][0] + (x[1][1],)))) \\\n",
    "    .sortBy(keyfunc=lambda x: x[1][1], ascending=False) \\\n",
    "    .coalesce(1)  # avoids having multiple (even hundreds) of part-* files as output (only one part-00000)\n",
    "\n",
    "# write all (ticker, (results)) pairs in file\n",
    "results.saveAsTextFile(output_filepath)\n",
    "\n",
    "# # create an RDD with the output string (todo, last map before/after coalesce(1) ?)\n",
    "# output_string = ('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(results[0][0],  # ticker\n",
    "#                                                  results[1][0],  # first date\n",
    "#                                                  results[1][1],  # last date\n",
    "#                                                  results[1][2],  # percent variation\n",
    "#                                                  results[1][3],  # minimum price\n",
    "#                                                  results[1][4]))  # max price\n",
    "# spark.sparkContext.parallelize([output_string]) \\\n",
    "#                   .saveAsTextFile(output_filepath)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job 2 <a name=\"job2\"></a>\n",
    "\n",
    "Generare un report contenente, per ciascun settore e per ciascun anno del periodo 2009-2018: \n",
    "\n",
    "- variazione percentuale della quotazione del settore nell'anno (somma prezzi di chiusura di tutte le azioni del settore, considerando la prima e l'ultima data di ogni azione aggregate) \n",
    "- azione del settore con incremento percentuale maggiore nell'anno (col valore)\n",
    "- azione del settore con maggior volume di transazioni nell'anno (con valore)\n",
    "\tordinare per nome del settore\n",
    "    \n",
    "Il report deve essere ordinato per nome del\n",
    "settore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce <a name=\"mapreduce2\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "ticker_to_sector = {}\n",
    "\n",
    "# process the historical stocks database (already cleaned from null sectors) before the join\n",
    "with open('historical_stocks_clean.csv') as hs_file:\n",
    "    # csv.reader reads the fields with a comma inside \" \" correctly (company name)\n",
    "    csv_reader = csv.reader(hs_file, delimiter=',')\n",
    "    is_first_line = True\n",
    "    for row in csv_reader:\n",
    "        if is_first_line:\n",
    "            # ignore csv header information\n",
    "            is_first_line = False\n",
    "        else:\n",
    "            ticker, _, _, sector, _ = row\n",
    "            ticker_to_sector[ticker] = sector\n",
    "\n",
    "# job2 requires a specific time frame to consider\n",
    "START_YEAR = 2009\n",
    "END_YEAR = 2018\n",
    "\n",
    "is_first_line = True\n",
    "\n",
    "# read lines from STDIN (historical_stock_prices dataset)\n",
    "for row in sys.stdin:\n",
    "    # ignores the first row, which contains column names\n",
    "    if is_first_line:\n",
    "        is_first_line = False\n",
    "        continue\n",
    "\n",
    "    # split the current row into fields (ignoring not needed ones)\n",
    "    ticker, _, closePrice, _, _, _, volume, date = row.strip().split(',')\n",
    "    date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "    # the ticker had a null sector, ignore it\n",
    "    if ticker not in ticker_to_sector:\n",
    "        continue\n",
    "\n",
    "    # write the separated fields to standard output, applying the necessary filtering\n",
    "    if START_YEAR <= date.year <= END_YEAR:\n",
    "        # the join adds a column sector\n",
    "        sector = ticker_to_sector[ticker]\n",
    "        print('{}\\t{}\\t{}\\t{}\\t{}'.format(\n",
    "            # shuffle and sort could be useful on these first three columns\n",
    "            sector,\n",
    "            ticker,\n",
    "            date,\n",
    "            closePrice,\n",
    "            volume))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# map each ticker for each sector and year to the values required to compute result\n",
    "#   tickerDataBySectorYear[('AAPL', 'TECH', 2012)] = {\n",
    "#       'first_close_date': 2012-01-01,\n",
    "#       'first_close_value': 50.5,\n",
    "#       'last_close_date': 2012-12-31,\n",
    "#       'last_close_value': 240,\n",
    "#       'total_volume': 300000}\n",
    "# after loading all the values it's useful to compute the percentage variation for the next step\n",
    "tickerDataBySectorYear = {}\n",
    "\n",
    "# structure to save the aggregated values from the previous one\n",
    "#   aggregatedSectorYearData[('TECH', 2012)] = {\n",
    "#       'sum_initial_close': 4000,\n",
    "#       'sum_final_close': 6000,\n",
    "#       'max_perc_var_ticker': 'AAPL',\n",
    "#       'max_perc_var_value': 75,\n",
    "#       'max_total_volume_ticker': 'AAPL',\n",
    "#       'max_total_volume_value': 3000000\n",
    "#       }\n",
    "aggregatedSectorYearData = {}\n",
    "\n",
    "\n",
    "def calculatePercVar(initialValue, finalValue):\n",
    "    return (finalValue - initialValue) / initialValue * 100\n",
    "\n",
    "\n",
    "# input comes from STDIN\n",
    "for line in sys.stdin:\n",
    "    # remove leading/trailing spaces\n",
    "    line = line.strip()\n",
    "    # parse the input elements\n",
    "    sector, ticker, date, closePrice, volume = line.split(\"\\t\")\n",
    "\n",
    "    # convert the fields in a row\n",
    "    try:\n",
    "        closePrice = float(closePrice)\n",
    "        volume = float(volume)\n",
    "        date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    except ValueError:\n",
    "        # if one of the numerical fields is not formatted correctly\n",
    "        continue\n",
    "\n",
    "    # save (in memory) the info of each ticker per year and sector (inefficient)\n",
    "    if (ticker, sector, date.year) not in tickerDataBySectorYear:\n",
    "        newTicker = {'first_close_date': date,\n",
    "                     'first_close_value': closePrice,\n",
    "                     'last_close_date': date,\n",
    "                     'last_close_value': closePrice,\n",
    "                     'total_volume': volume}\n",
    "        tickerDataBySectorYear[(ticker, sector, date.year)] = newTicker\n",
    "    # the ticker in that year (with that sector) has been seen, update it\n",
    "    else:\n",
    "        currTicker = tickerDataBySectorYear[(ticker, sector, date.year)]\n",
    "        if date < currTicker['first_close_date']:\n",
    "            currTicker['first_close_date'] = date\n",
    "            currTicker['first_close_value'] = closePrice\n",
    "        if date > currTicker['last_close_date']:\n",
    "            currTicker['last_close_date'] = date\n",
    "            currTicker['last_close_value'] = closePrice\n",
    "        currTicker['total_volume'] += volume\n",
    "\n",
    "# aggregate the single ticker and year data by sector\n",
    "for (ticker, sector, year) in tickerDataBySectorYear:\n",
    "    currTicker = tickerDataBySectorYear[(ticker, sector, year)]\n",
    "    initialClose = currTicker['first_close_value']\n",
    "    finalClose = currTicker['last_close_value']\n",
    "    percVar = calculatePercVar(initialClose, finalClose)\n",
    "    volume = currTicker['total_volume']\n",
    "    # create a new dict to save the data\n",
    "    if (sector, year) not in aggregatedSectorYearData:\n",
    "        newData = {'sum_initial_close': initialClose,\n",
    "                   'sum_final_close': finalClose,\n",
    "                   'max_perc_var_ticker': ticker,\n",
    "                   'max_perc_var_value': percVar,\n",
    "                   'max_total_volume_ticker': ticker,\n",
    "                   'max_total_volume_value': volume}\n",
    "        aggregatedSectorYearData[(sector, year)] = newData\n",
    "    # update the existing data\n",
    "    else:\n",
    "        currData = aggregatedSectorYearData[(sector, year)]\n",
    "        currData['sum_initial_close'] += initialClose\n",
    "        currData['sum_final_close'] += finalClose\n",
    "        if percVar > currData['max_perc_var_value']:\n",
    "            currData['max_perc_var_ticker'] = ticker\n",
    "            currData['max_perc_var_value'] = percVar\n",
    "        if volume > currData['max_total_volume_value']:\n",
    "            currData['max_total_volume_ticker'] = ticker\n",
    "            currData['max_total_volume_value'] = volume\n",
    "\n",
    "\n",
    "# sort the results based on sector\n",
    "# aggregatedSectorYearData entries are in the format: ('Sector', Year): {'min': 1, 'max': 2, ...}\n",
    "sortedResults = sorted(aggregatedSectorYearData.items(),\n",
    "                       # takes the first argument in (key, value), and the first argument in key=(sector, year)\n",
    "                       # it will return a list of ordered keys (by sector and then year)\n",
    "                       key=lambda single_entry: single_entry[0],\n",
    "                       # orders the sectors (and years) by ascending alphabetical order\n",
    "                       reverse=False)\n",
    "\n",
    "# each result has the format of aggregatedSectorYearData entries, plus a new field for the total percent variation\n",
    "for result in sortedResults:\n",
    "    sector = result[0][0]\n",
    "    year = result[0][1]\n",
    "\n",
    "    currResult = aggregatedSectorYearData[(sector, year)]\n",
    "    initialCloseSum = currResult['sum_initial_close']\n",
    "    finalCloseSum = currResult['sum_final_close']\n",
    "    currResult['total_perc_var'] = calculatePercVar(initialCloseSum, finalCloseSum)\n",
    "\n",
    "# more human readable text file, but causes troubles when opening in a spreadsheet\n",
    "#   print('{:<25s}\\t{}\\t{:<15}%\\t{:>5s}\\t{:<15}%\\t{:>5s}\\t{:<15}'.format(\n",
    "    print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(\n",
    "        sector,\n",
    "        year,\n",
    "        currResult['total_perc_var'],\n",
    "        currResult['max_perc_var_ticker'],\n",
    "        currResult['max_perc_var_value'],\n",
    "        currResult['max_total_volume_ticker'],\n",
    "        currResult['max_total_volume_value']))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive <a name=\"hive2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per questo job sono state create diverse tabelle esterne, per chiarezza divise a seconda del task per cui esse hanno un'utilità:\n",
    "\n",
    "UTILI PER IL TASK A\n",
    "\n",
    "* Per ogni settore estrare l'anno dalle date dei prezzi\n",
    "\n",
    "\n",
    "```SQL\n",
    "create table sector_2_date as\n",
    "select distinct d2.sector, extract(year from d1.price_date)\n",
    "from historical_stock_prices(size) as d1 left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "order by d2.sector, `_c1`;\n",
    "alter table sector_2_date change `_c1` year int;\n",
    "```\n",
    "\n",
    "* Per ogni settore, anno e ticker estrae la data della prima e dell'ultima quotazione dell'anno.\n",
    "\n",
    "\n",
    "```SQL\n",
    "create table sector_ticker_min_max as\n",
    "select d2.sector, sd.year, d1.ticker, min(d1.price_date) as first_date, max(d1.price_date) as last_date\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "left join sector_2_date as sd on d2.sector = sd.sector and sd.year = extract(year from d1.price_date)\n",
    "where sd.year >=2009 and sd.year <= 2018\n",
    "group by d2.sector, sd.year, d1.ticker\n",
    "order by sector, year, d1.ticker;\n",
    "```\n",
    "\n",
    "* Per ogni settore e anno calcola la somma di tutte e quotazioni nella prima data dell'anno per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_to_min_quot as\n",
    "select d2.sector, sm.year, sum(d1.close_price) as first_quot\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "join sector_ticker_min_max as sm on d2.sector = sm.sector and sm.year = extract(year from d1.price_date) and d1.ticker = sm.ticker\n",
    "where d1.price_date = sm.first_date\n",
    "group by d2.sector, sm.year\n",
    "order by d2.sector, sm.year;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni settore e anno calcola la somma di tutte e quotazioni nell'ultima data dell'anno per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_to_max_quot as\n",
    "select d2.sector, sm.year, sum(d1.close_price) as last_quot\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "join sector_ticker_min_max as sm on d2.sector = sm.sector and sm.year = extract(year from d1.price_date) and d1.ticker = sm.ticker\n",
    "where d1.price_date = sm.last_date and  d2.sector != \"N/A\"\n",
    "group by d2.sector, sm.year\n",
    "order by d2.sector, sm.year;\n",
    "```\n",
    "\n",
    "UTILI PER IL TASK B\n",
    "\n",
    "* Per ogni settore e anno estrae il ticker con la sua prima quotazione per quel settore e in quell'anno.\n",
    "\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_tickerFirstQuotation as\n",
    "select d2.sector, sm.year, d1.ticker, close_price as first_quotation\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "left join sector_ticker_min_max as sm on d2.sector = sm.sector and d1.ticker = sm.ticker\n",
    "where d1.price_date = sm.first_date\n",
    "order by d2.sector, sm.year;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni settore e anno estrae il ticker con la sua ultima quotazione per quel settore e in quell'anno.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_tickerLastQuotation as\n",
    "select d2.sector, sm.year, d1.ticker, close_price as last_quotation\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "left join sector_ticker_min_max as sm on d2.sector = sm.sector and d1.ticker = sm.ticker\n",
    "where d1.price_date = sm.last_date\n",
    "order by d2.sector, sm.year;\n",
    "```\n",
    "\n",
    "* Per ogni settore e anno estrae il ticker con la sua prima e ultima quotazione per quel settore e in quell'anno (Join delle due tabelle precedenti).\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_tickerFirstLastQuotation as\n",
    "select s1.sector, s1.year, s1.ticker, s1.first_quotation, s2.last_quotation\n",
    "from sector_year_to_tickerFirstQuotation as s1\n",
    "left join sector_year_to_tickerLastQuotation as s2\n",
    "on (s1.sector = s2.sector and s1.year = s2.year and s1.ticker = s2.ticker)\n",
    "order by s1.sector, s1.year;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni settore, anno e ticker calcola la variazione percentuale del ticker in quell'anno per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_variation as\n",
    "select sector, year, ticker, max(((last_quotation - first_quotation)/first_quotation)*100) as variation\n",
    "from sector_year_to_tickerFirstLastQuotation\n",
    "group by sector, year, ticker;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni settore e anno calcola la variazione massima avuta in quell'anno e per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_maxVariation as\n",
    "select sector, year, max(variation) as max_variation\n",
    "from sector_year_to_variation\n",
    "group by sector, year;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni settore e anno estrae il ticker che ha avuto la variazione percentuale massima in quell'anno e per quel settore, con l'indicazione di tale variazione.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_maxTicker as\n",
    "select smax.sector, smax.year, sv.ticker, smax.max_variation\n",
    "from sector_year_to_maxVariation as smax\n",
    "left join sector_year_to_variation as sv on smax.sector = sv.sector and smax.year = sv.year\n",
    "where max_variation = variation;\n",
    "```\n",
    "\n",
    "\n",
    "UTILI PER IL TASK C\n",
    "\n",
    "* Per ogni settore, anno e ticker calcola la somma dei volumi dei ticker in quell'anno e per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_ticker_to_volumeSum as\n",
    "select d2.sector, year(d1.price_date) as price_year, d1.ticker, sum(d1.volume) as volume\n",
    "from historical_stock_prices(size) as d1\n",
    "join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "group by d2.sector, year(d1.price_date), d1.ticker;\n",
    "```\n",
    "\n",
    "* Per ogni settore e anno estrae la somma di volumi massima in quell'anno e per quel settore.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_to_maxVolume as\n",
    "select sector, price_year, max(volume) as maxVolume\n",
    "from sector_year_ticker_to_volumeSum\n",
    "group by sector, price_year\n",
    "order by sector, price_year;\n",
    "```\n",
    "\n",
    "* Per ogni settore e anno estrae il ticker che ha la somma di volumi massima in quell'anno e per quel settore, con indicazione di tale somma.\n",
    "\n",
    "```SQL\n",
    "create table sector_year_toMaxVolumeTicker as\n",
    "select ayt.sector, ayt.price_year, ayt.ticker as v_ticker, ayt.volume\n",
    "from sector_year_ticker_to_volumeSum as ayt\n",
    "left join sector_year_to_maxVolume as aym on ayt.sector = aym.sector and ayt.price_year = aym.price_year\n",
    "where volume = maxVolume;\n",
    "```\n",
    "\n",
    "QUERY FINALE\n",
    "\n",
    "* Mette insieme tutte le precedenti tabelle per estrarre, per ogni settore e anno, la  variazione percentuale della quotazione del settore nell’anno, l’azione del settore che ha avuto il maggior incremento percentuale nell’anno (con indicazione dell’incremento), l’azione del settore che ha avuto il maggior  volume  di  transazioni nell’anno(con  indicazione  del  volume).\n",
    "\n",
    "```SQL\n",
    "create table job2_hive as\n",
    "select d2.sector, smin.year, min(((smax.last_quot - smin.first_quot)/smin.first_quot)*100) as variation, max(sy.ticker), max(sy.max_variation), min(v_ticker), max(syv.volume)\n",
    "from historical_stock_prices(size) as d1\n",
    "left join historical_stocks_clean as d2 on d1.ticker = d2.ticker\n",
    "left join sector_to_min_quot as smin on d2.sector = smin.sector and smin.year = extract(year from d1.price_date)\n",
    "left join sector_to_max_quot as smax on d2.sector = smax.sector and smax.year = extract(year from d1.price_date)\n",
    "left join sector_year_to_maxTicker sy on d2.sector = sy.sector and sy.year = extract(year from d1.price_date)\n",
    "left join sector_year_toMaxVolumeTicker as syv on d2.sector = syv.sector and syv.price_year = extract(year from d1.price_date)\n",
    "where smin.year >=2009 and smin.year <= 2018 and smax.year >=2009 and smax.year <= 2018 and d2.sector != \"N/A\"\n",
    "group by d2.sector, smin.year\n",
    "order by d2.sector, smin.year;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark <a name=\"spark2\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"spark application\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# create parser and set its arguments\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# the second dataset needs double-quotes (\"\") escaping to parse correctly\n",
    "def parse_line(row):\n",
    "    csv_reader = csv.reader([row], delimiter=',')\n",
    "    return next(csv_reader)\n",
    "\n",
    "\n",
    "def min_value(a, b, val_type, index):\n",
    "    if val_type == 'date':\n",
    "        val_a = datetime.strptime(a[index], '%Y-%m-%d').date()\n",
    "        val_b = datetime.strptime(b[index], '%Y-%m-%d').date()\n",
    "    else:\n",
    "        val_a = float(a[index])\n",
    "        val_b = float(b[index])\n",
    "    if val_a <= val_b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "\n",
    "def max_value(a, b, val_type, index):\n",
    "    if val_type == 'date':\n",
    "        val_a = datetime.strptime(a[index], '%Y-%m-%d').date()\n",
    "        val_b = datetime.strptime(b[index], '%Y-%m-%d').date()\n",
    "    else:\n",
    "        val_a = float(a[index])\n",
    "        val_b = float(b[index])\n",
    "    if val_a >= val_b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "\n",
    "def calculate_percent_variation(initial, final):\n",
    "    return (float(final) - float(initial)) / float(initial) * 100\n",
    "\n",
    "\n",
    "def sum_tuple(a, b):\n",
    "    val_a = (float(a[0]), float(a[1]))\n",
    "    val_b = (float(b[0]), float(b[1]))\n",
    "    sum_tuples = [sum(i) for i in zip(*(val_a, val_b))]\n",
    "    return tuple(sum_tuples)\n",
    "\n",
    "\n",
    "# fields' index in a row (in historical_stock_prices.csv)\n",
    "TICKER = 0\n",
    "OPEN = 1\n",
    "CLOSE = 2\n",
    "ADJ_CLOSE = 3\n",
    "MIN = 4\n",
    "MAX = 5\n",
    "VOLUME = 6\n",
    "DATE = 7\n",
    "\n",
    "# fields' index in a row (historical_stocks.csv)\n",
    "TICKER = 0\n",
    "EXCHANGE = 1\n",
    "NAME = 2\n",
    "SECTOR = 3\n",
    "INDUSTRY = 4\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_hsp\", type=str, help=\"Input file historical stock prices\")\n",
    "parser.add_argument(\"--input_hs\", type=str, help=\"Input file historical stocks\")\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"Output folder path\")\n",
    "\n",
    "# parse arguments\n",
    "args = parser.parse_args()\n",
    "input_hsp, input_hs, output_filepath = args.input_hsp, args.input_hs, args.output_path\n",
    "\n",
    "# initialize SparkSession\n",
    "# with the proper configuration\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Job2 Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# spark.sparkContext.textFile(filepath) returns an RDD\n",
    "# with a record for each line in the input file\n",
    "historical_stock_prices = sc.textFile(input_hsp).cache()\n",
    "# this dataset was already cleaned from null sectors\n",
    "historical_stocks = sc.textFile(input_hs).cache()\n",
    "\n",
    "# job2 requires to only consider years 2009-2018\n",
    "# after this point hsp is in the format: (key=(ticker), value=(close_price, volume, date))\n",
    "hsp = historical_stock_prices.map(lambda line: line.strip().split(',')) \\\n",
    "    .filter(lambda line: line[TICKER] != 'ticker' and int(line[DATE][0:4]) in range(2009, 2018+1)) \\\n",
    "    .map(lambda line: (line[TICKER], (line[CLOSE], line[VOLUME], line[DATE])))\n",
    "\n",
    "# we need to get the sector for each ticker (other fields are not important)\n",
    "# hs is formatted as (ticker, sector)\n",
    "hs = historical_stocks.map(lambda line: parse_line(line)) \\\n",
    "    .filter(lambda line: line[TICKER] != 'ticker') \\\n",
    "    .map(lambda line: (line[TICKER], line[SECTOR]))\n",
    "\n",
    "# adds the sector to each ticker in hsp via join\n",
    "# after the join: (ticker, ((close, volume, date), (sector)))\n",
    "# the tuples get transformed to: (key=(sector, year, ticker), value=(close, volume, date))\n",
    "hsp_sector = hsp.join(hs) \\\n",
    "    .map(lambda x: ((x[1][1], int(x[1][0][2][0:4]), x[0]), x[1][0]))\n",
    "\n",
    "# this calculates the first and last quotation dates (with values) of each (sector, ticker, year) tuple\n",
    "# each of these RDDs returns: ((sector, year, ticker), (close))\n",
    "first_quotation_close = hsp_sector.reduceByKey(lambda a, b: min_value(a, b, 'date', 2)) \\\n",
    "    .map(lambda x: (x[0], x[1][0]))\n",
    "last_quotation_close = hsp_sector.reduceByKey(lambda a, b: max_value(a, b, 'date', 2)) \\\n",
    "    .map(lambda x: (x[0], x[1][0]))\n",
    "\n",
    "# after join: ((sector, year, ticker), (first_close, last_close))\n",
    "# we add the percent variation: ((sector, year, ticker), (first_close, last_close, percent_var))\n",
    "ticker_percent_variation = first_quotation_close.join(last_quotation_close) \\\n",
    "    .map(lambda x: (x[0], (x[1] + (calculate_percent_variation(x[1][0], x[1][1]), ))))\n",
    "\n",
    "# calculates the ticker with maximum percent increase for each (sector, year)\n",
    "# outputs: ((sector, year), (max_ticker, percent_increase))\n",
    "ticker_max_percent_var = ticker_percent_variation.map(lambda x: ((x[0][0], x[0][1]), (x[0][2], x[1][2]))) \\\n",
    "    .reduceByKey(lambda a, b: max_value(a, b, 'float', 1))\n",
    "\n",
    "# sums of all the volumes' sum (line[1][1]) per (sector, year, ticker)\n",
    "# then it returns the ticker that has the max volume: ((sector, year), (max_ticker, volume))\n",
    "ticker_max_volume = hsp_sector.map(lambda line: (line[0], line[1][1])) \\\n",
    "    .reduceByKey(lambda a, b: int(a) + int(b)) \\\n",
    "    .map(lambda line: ((line[0][0], line[0][1]), (line[0][2], line[1]))) \\\n",
    "    .reduceByKey(lambda a, b: max_value(a, b, 'int', 1))\n",
    "\n",
    "# input: ((sector, year, ticker), (first_close, last_close, percent_var))\n",
    "# the first map removes the percent_var from the value of the line, and the ticker from the key\n",
    "# output: ((sector, year), (sector_year_percent_var))\n",
    "sector_year_percent_variation = ticker_percent_variation.map(lambda x: ((x[0][0], x[0][1]), (x[1][0], x[1][1]))) \\\n",
    "    .reduceByKey(lambda a, b: sum_tuple(a, b)) \\\n",
    "    .map(lambda x: (x[0], calculate_percent_variation(x[1][0], x[1][1])))\n",
    "\n",
    "# aggregates the sector variation and the tickers with max variation and volume for a given (sector, year) pair\n",
    "# after first join: ((sector, year), (sector_percent_var, (max_var_ticker, percent_increase)))\n",
    "# after second join: ((sector, year), ((sector_var, ticker, percent_increase), (max_ticker, volume)))\n",
    "# it will result in ((sector, year), (sector_var, ticker, percent_increase, ticker, volume))\n",
    "results = sector_year_percent_variation.join(ticker_max_percent_var) \\\n",
    "    .map(lambda x: (x[0], ((x[1][0], ) + (x[1][1])))) \\\n",
    "    .join(ticker_max_volume) \\\n",
    "    .map(lambda x: (x[0], (x[1][0] + x[1][1]))) \\\n",
    "    .sortBy(keyfunc=lambda x: x[0], ascending=True) \\\n",
    "    .coalesce(1)\n",
    "\n",
    "# # write all ((sector, year), (results...)) in a file\n",
    "results.saveAsTextFile(output_filepath)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job 3 <a name=\"job3\"></a>\n",
    "\n",
    "Generare le coppie di aziende che si somigliano (sulla base di una soglia = 1%) in termini di\n",
    "variazione percentuale mensile nell’anno 2017. \n",
    "\n",
    "Mostrare l’andamento mensile delle due aziende nel formato:\n",
    "\n",
    "- 1:{Apple, Intel}:   \n",
    "    - GEN: Apple +2%, Intel +2,5%, \n",
    "    - FEB: Apple +3%, Intel +2,7%, \n",
    "    - MAR: Apple +0,5%, Intel +1,2%, ...\n",
    "- 2:{Amazon, IBM}:    \n",
    "    - GEN: Amazon +1%, IBM +0,5%, \n",
    "    - FEB: Amazon +0,7%, IBM +0,5%, \n",
    "    - MAR: Amazon +1,4%, IBM +0,7%, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce <a name=\"mapreduce3\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"firstMapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "is_first_line = True\n",
    "\n",
    "# read lines from STDIN\n",
    "for row in sys.stdin:\n",
    "    # ignores the first row, which contains column names\n",
    "    if is_first_line:\n",
    "        is_first_line = False\n",
    "        continue\n",
    "\n",
    "    # split the current row into fields (ignoring not needed ones)\n",
    "    ticker, _, closePrice, _, _, _, _, date = row.strip().split(',')\n",
    "    date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "    # filter out all the years but 2017\n",
    "    if date.year != 2017:\n",
    "        continue\n",
    "\n",
    "    # write the separated fields to standard output\n",
    "    print('{}\\t{}\\t{}'.format(\n",
    "        ticker,\n",
    "        closePrice,\n",
    "        date))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"firstReducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# saves the monthly first and last close price for each ticker (along with their dates for comparing)\n",
    "# tickerToMonthVar = {'AAPL':\n",
    "#                       { 1: {'first_close': 15, 'last_close': 20, 'first_date': .., 'last_date': ..},\n",
    "#                         2: {'first_close': 20, 'last_close': 2, ...}\n",
    "#                         ...\n",
    "#                         12: {'first_close': 5, 'last_close': 2, ...} ...}\n",
    "tickerToMonthVar = {}\n",
    "\n",
    "\n",
    "def calculatePercVar(initialValue, finalValue):\n",
    "    return (finalValue - initialValue) / initialValue * 100\n",
    "\n",
    "\n",
    "# input comes from STDIN (the previous mapper)\n",
    "for row in sys.stdin:\n",
    "    # parse the input elements\n",
    "    ticker, closePrice, date = row.strip().split(\"\\t\")\n",
    "\n",
    "    # convert the fields in a row\n",
    "    try:\n",
    "        closePrice = float(closePrice)\n",
    "        date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    except ValueError:\n",
    "        # if one of the fields is not formatted correctly\n",
    "        continue\n",
    "\n",
    "    # the ticker and month are already in the dict, update them\n",
    "    if (ticker in tickerToMonthVar) and (date.month in tickerToMonthVar[ticker]):\n",
    "        currTickerMonth = tickerToMonthVar[ticker][date.month]\n",
    "        if date < currTickerMonth['first_date']:\n",
    "            currTickerMonth['first_close'] = closePrice\n",
    "            currTickerMonth['first_date'] = date\n",
    "        if date > currTickerMonth['last_date']:\n",
    "            currTickerMonth['last_close'] = closePrice\n",
    "            currTickerMonth['last_date'] = date\n",
    "    # insert ticker data in the dict\n",
    "    else:\n",
    "        currTickerMonth = {'first_close': closePrice,\n",
    "                           'last_close': closePrice,\n",
    "                           'first_date': date,\n",
    "                           'last_date': date}\n",
    "        if ticker not in tickerToMonthVar:\n",
    "            tickerToMonthVar[ticker] = {date.month: currTickerMonth}\n",
    "        else:\n",
    "            tickerToMonthVar[ticker][date.month] = currTickerMonth\n",
    "\n",
    "\n",
    "# print the data structure calculating the monthly percent variation\n",
    "for ticker in tickerToMonthVar:\n",
    "    yearData = tickerToMonthVar[ticker]\n",
    "    # iterate over all months for the ticker\n",
    "    for month in yearData:\n",
    "        initialClose = yearData[month]['first_close']\n",
    "        finalClose = yearData[month]['last_close']\n",
    "        # prints ('AAPL', 3, 25.3) separating each month for the same ticker (put together in next mapreduce)\n",
    "        print('{}\\t{}\\t{}'.format(ticker, month, calculatePercVar(initialClose, finalClose)))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"secondMapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    ticker, month, percVar = line.strip().split('\\t')\n",
    "    print('{}\\t{}\\t{}'.format(ticker, month, percVar))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"secondReducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "THRESHOLD = 1\n",
    "MONTHS_LITERAL = {1: 'GEN', 2: 'FEB', 3: 'MAR', 4: 'APR', 5: 'MAG', 6: 'GIU', 7: 'LUG', 8: 'AGO', 9: 'SET',\n",
    "                  10: 'OTT', 11: 'NOV', 12: 'DIC'}\n",
    "\n",
    "# the dict aggregates all months for each ticker\n",
    "# tickerToMonthsVar = {'AAPL': {0: 13.5, 1: 12.0, ... , 12: -5.3}, ...}\n",
    "tickerToMonthsVar = {}\n",
    "\n",
    "# structure to contain the cross product (without duplicates or inverted pairs)\n",
    "# crossProduct = {('AAPL', 'AMZN'): {1: (2, 2.6), 2: (-1, 3.7), ... },\n",
    "#                 ('AAPL', 'BTP'): {1: (2, -1), 2: (-1, 3.4), ...}}\n",
    "crossProduct = {}\n",
    "\n",
    "\n",
    "# generates a merged pair to insert in the crossProduct data structure\n",
    "# it will return None if the pair of tickers is not similar enough (based on 1% threshold of percVar for each month)\n",
    "def mergeTickerPair(ticker1, ticker2, tickerData):\n",
    "    result = {}\n",
    "    ticker1Data = tickerData[ticker1]\n",
    "    ticker2Data = tickerData[ticker2]\n",
    "    # the comparison will fail if the months data are not consistent\n",
    "    if ticker1Data.keys() != ticker2Data.keys():\n",
    "        return None\n",
    "    for month in ticker1Data:\n",
    "        percVar1 = ticker1Data[month]\n",
    "        percVar2 = ticker2Data[month]\n",
    "        month = MONTHS_LITERAL[month]\n",
    "        if abs(percVar1 - percVar2) <= THRESHOLD:\n",
    "            result[month] = (percVar1, percVar2)\n",
    "        else:\n",
    "            return None\n",
    "    return result\n",
    "\n",
    "\n",
    "# each month is unique for a given ticker (we assume no duplicates)\n",
    "for row in sys.stdin:\n",
    "    # parse the input elements\n",
    "    ticker, month, percVar = row.strip().split(\"\\t\")\n",
    "\n",
    "    # convert the fields in a row\n",
    "    try:\n",
    "        month = float(month)\n",
    "        percVar = float(percVar)\n",
    "    except ValueError:\n",
    "        # if one of the fields is not formatted correctly\n",
    "        continue\n",
    "\n",
    "    if ticker not in tickerToMonthsVar:\n",
    "        tickerToMonthsVar[ticker] = {month: percVar}\n",
    "    else:\n",
    "        tickerToMonthsVar[ticker][month] = percVar\n",
    "\n",
    "# generates all the possible (and useful) pairs of the cross product\n",
    "for ticker1 in tickerToMonthsVar:\n",
    "    for ticker2 in tickerToMonthsVar:\n",
    "        if (ticker1, ticker2) in crossProduct or (ticker2, ticker1) in crossProduct or ticker1 == ticker2:\n",
    "            continue\n",
    "        else:\n",
    "            mergedPair = mergeTickerPair(ticker1, ticker2, tickerToMonthsVar)\n",
    "            if mergedPair is None:\n",
    "                continue\n",
    "            else:\n",
    "                crossProduct[(ticker1, ticker2)] = mergedPair\n",
    "\n",
    "for pair in crossProduct:\n",
    "    print('{}\\t{}'.format(\n",
    "        pair,\n",
    "        crossProduct[pair]))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive <a name=\"hive3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per l'ultimo job vengono create diverse tabelle esterne che saranno poi utilizzate per costruire la tabella finale:\n",
    "\n",
    "* Filtra il database per mostrare solo i dati del 2017\n",
    "\n",
    "```SQL\n",
    "create table 2017_data as\n",
    "select ticker, price_date, extract(month from price_date), close_price\n",
    "from historical_stock_prices(size)\n",
    "where extract(year from price_date) = 2017\n",
    "order by ticker, price_date;\n",
    "alter table 2017_data change `_c2` month int;\n",
    "```\n",
    "\n",
    "* Per ogni ticker e mese estrae il primo e l'ultimo prezzo di chiusura del ticker in quel mese\n",
    "\n",
    "```SQL\n",
    "create table ticker_month_to_max_min_date as\n",
    "select ticker, month, min(price_date) as min_date, max(price_date) as max_date\n",
    "from 2017_data\n",
    "group by ticker, month;\n",
    "```\n",
    "\n",
    "* Per ogni ticker e mese estrae la prima quotazione di quel ticker in quel mese\n",
    "\n",
    "```SQL\n",
    "create table ticker_to_first_month_quotation as\n",
    "select d.ticker, d.month, d.close_price\n",
    "from 2017_data as d\n",
    "left join ticker_month_to_max_min_date as tm on d.ticker = tm.ticker\n",
    "where price_date = min_date;\n",
    "```\n",
    "\n",
    "\n",
    "* Per ogni ticker e mese estrae l'ultima quotazione di quel ticker in quel mese\n",
    "\n",
    "```SQL\n",
    "create table ticker_to_last_month_quotation as\n",
    "select d.ticker, d.month, d.close_price\n",
    "from 2017_data as d\n",
    "left join ticker_month_to_max_min_date as tm on d.ticker = tm.ticker\n",
    "where price_date = max_date;\n",
    "```\n",
    "\n",
    "* Per ogni ticker e mese estrae la prima e l'ultima quotazione del ticker in quel mese (join tra le due tabelle precedenti)\n",
    "\n",
    "```SQL\n",
    "create table ticker_to_first_last_month_quotation as\n",
    "select first.ticker, first.month, first.close_price as first_quotation, last.close_price as last_quotation\n",
    "from ticker_to_first_month_quotation as first\n",
    "left join ticker_to_last_month_quotation as last\n",
    "on first.ticker = last.ticker and first.month = last.month\n",
    "order by ticker, month;\n",
    "```\n",
    "\n",
    "* Per ogni ticker e mese calcola la variazione percentuale di quel ticker in quel mese\n",
    "\n",
    "```SQL\n",
    "create table ticker_month_to_variation as\n",
    "select ticker, month, (((last_quotation - first_quotation)/first_quotation)*100) as variation\n",
    "from ticker_to_first_last_month_quotation\n",
    "order by ticker, month;\n",
    "```\n",
    "\n",
    "* Per ogni coppia di ticker e per ogni mese estrae la variaizone percentuale del primo e del secondo ticker per quel mese \n",
    "\n",
    "```SQL\n",
    "create table variations_comparison as\n",
    "select t1.ticker as ticker_1, t2.ticker as ticker_2, t1.month, cast(t1.variation as decimal(10,2)) as variation_1, cast(t2.variation as decimal(10,2)) as variation_2\n",
    "from ticker_month_to_variation as t1, ticker_month_to_variation as t2\n",
    "where t1.ticker > t2.ticker and t1.month = t2.month and (abs(t1.variation - t2.variation) <= 1)\n",
    "order by ticker_1, ticker_2, t1.month;\n",
    "```\n",
    "\n",
    "* Crea la tabella dei risultati raggruppando per coppie di ticker e trasformando i valori della colonna \"month\" in nuove colonne, ognuna per ogni mese, popolate dai rispettivi valori per quel mese.\n",
    "\n",
    "```SQL\n",
    "create table raw_results as\n",
    "select ticker_1 as t1, ticker_2 as t2,\n",
    "max(case when month=\"1\" then \"GEN:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as gen,\n",
    "max(case when month=\"2\" then \"FEB:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as feb,\n",
    "max(case when month=\"3\" then \"MAR:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as mar,\n",
    "max(case when month=\"4\" then \"APR:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as apr,\n",
    "max(case when month=\"5\" then \"MAG:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as mag,\n",
    "max(case when month=\"6\" then \"GIU:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as giu,\n",
    "max(case when month=\"7\" then \"LUG:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as lug,\n",
    "max(case when month=\"8\" then \"AGO:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as ago,\n",
    "max(case when month=\"9\" then \"SET:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as sep,\n",
    "max(case when month=\"10\" then \"OTT:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as ott,\n",
    "max(case when month=\"11\" then \"NOV:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as nov,\n",
    "max(case when month=\"12\" then \"DIC:\"||\" \"||\"(\"||variation_1||\"%\"||\", \"||variation_2||\"%\"||\")\" else \"\" end) as dic\n",
    "from variations_comparison\n",
    "group by ticker_1, ticker_2;\n",
    "```\n",
    "\n",
    "* Nel mostrare i risutati si filtra la tabella finale affinché mostri soltanto le coppie di ticker che si somigliano in tutti i mesi.\n",
    "\n",
    "```SQL\n",
    "create table job3_hive as\n",
    "select * from raw_results\n",
    "where (gen!=\"\" and feb!=\"\" and mar!=\"\" and apr!=\"\" and mag!=\"\" and giu!=\"\" and lug!=\"\" and ago!=\"\"\n",
    "and sep!=\"\" and ott!=\"\" and nov!=\"\" and dic!=\"\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark <a name=\"spark3\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"spark application\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import pyspark\n",
    "\n",
    "# create parser and set its arguments\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def min_price_and_date(x, y):\n",
    "    x_price = x[1]\n",
    "    y_price = y[1]\n",
    "    x_date = x[2]\n",
    "    y_date = y[2]\n",
    "    if x_date <= y_date:\n",
    "        return x[0], x_price, x_date\n",
    "    else:\n",
    "        return y[0], y_price, y_date\n",
    "\n",
    "\n",
    "def max_price_and_date(x, y):\n",
    "    x_price = x[1]\n",
    "    y_price = y[1]\n",
    "    x_date = x[2]\n",
    "    y_date = y[2]\n",
    "    if x_date >= y_date:\n",
    "        return x[0], x_price, x_date\n",
    "    else:\n",
    "        return y[0], y_price, y_date\n",
    "\n",
    "\n",
    "def calculate_percent_variation(initial, final):\n",
    "    return (float(final) - float(initial)) / float(initial) * 100\n",
    "\n",
    "\n",
    "def compare_months_variations(month_list1, month_list2):\n",
    "    zip_object = zip(month_list1, month_list2)\n",
    "    for month_var1, month_var2 in zip_object:\n",
    "        if abs(month_var1[1] - month_var2[1]) > THRESHOLD:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def merge_months_variations(month_list1, month_list2):\n",
    "    result_list = []\n",
    "    zip_object = zip(month_list1, month_list2)\n",
    "    for month_var1, month_var2 in zip_object:\n",
    "        result_list.append((MONTHS_LITERAL[month_var1[0]], (month_var1[1], month_var2[1])))\n",
    "    return result_list\n",
    "\n",
    "\n",
    "# fields' index in a row (in historical_stock_prices.csv)\n",
    "TICKER = 0\n",
    "OPEN = 1\n",
    "CLOSE = 2\n",
    "ADJ_CLOSE = 3\n",
    "MIN = 4\n",
    "MAX = 5\n",
    "VOLUME = 6\n",
    "DATE = 7\n",
    "\n",
    "# defines when two tickers are similar based on their monthly percent variation\n",
    "THRESHOLD = 1\n",
    "\n",
    "MONTHS_LITERAL = {1: 'GEN', 2: 'FEB', 3: 'MAR', 4: 'APR', 5: 'MAG', 6: 'GIU', 7: 'LUG', 8: 'AGO', 9: 'SET',\n",
    "                  10: 'OTT', 11: 'NOV', 12: 'DIC'}\n",
    "\n",
    "# Create parser and set its arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_path\", type=str, help=\"Inout file path\")\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"Output folder path\")\n",
    "\n",
    "# parse parameters\n",
    "args = parser.parse_args()\n",
    "input_filepath, output_filepath = args.input_path, args.output_path\n",
    "\n",
    "# initialize SparkSession\n",
    "# with the proper configuration\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Job3 Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# spark.sparkContext.textFile(filepath) returns an RDD\n",
    "# with a record for each line in the input file\n",
    "historical_stock_prices = sc.textFile(input_filepath).cache()\n",
    "# historical_stock_prices = sc.textFile(input_filepath).persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# Strip and split by \",\" records in rdd\n",
    "split_input = historical_stock_prices.map(lambda line: line.strip().split(','))\n",
    "\n",
    "# filter the header row and all the years but 2017\n",
    "# Map into a new RDD -> Key = (Ticker), value = (close_price, date)\n",
    "ticker_close_date = split_input.filter(lambda x: x[DATE][0:4] == '2017') \\\n",
    "    .map(lambda x: (x[TICKER], float(x[CLOSE]), datetime.strptime(x[DATE], \"%Y-%m-%d\").date()))\n",
    "\n",
    "# Map into a new RDD -> Key = (Ticker, month), value = (Ticker, close_price, date)\n",
    "ticker_month_to_list = ticker_close_date.map(lambda x: ((x[0], x[2].month), x))\n",
    "\n",
    "# Reduce by key to get, for each ticker and month, the first date and close price of the month\n",
    "# Map into a new RDD -> Key = (Ticker, month), value = (close price at the first date of the month for that ticker)\n",
    "ticker_month_to_mindate = ticker_month_to_list.reduceByKey(min_price_and_date) \\\n",
    "    .map(lambda x: (x[0], x[1][1]))\n",
    "\n",
    "# Reduce by key to get, for each ticker and month, the last date and close price of the month\n",
    "# Map into a new RDD -> Key = (Ticker, month), value = (close price at the last date of the month for that ticker)\n",
    "ticker_month_to_maxdate = ticker_month_to_list.reduceByKey(max_price_and_date) \\\n",
    "    .map(lambda x: (x[0], x[1][1]))\n",
    "\n",
    "# Join ticker_month_to_mindate and ticker_month_to_maxdate on key (Ticker, month)\n",
    "# Map into a new RDD -> Key = (Ticker, month), value (price percent variation for that ticker in that month)\n",
    "ticker_month_variation = ticker_month_to_mindate.join(ticker_month_to_maxdate) \\\n",
    "    .map(lambda x: (x[0], calculate_percent_variation(x[1][0], x[1][1])))\n",
    "\n",
    "# maps to have (ticker: (month, percent_var))\n",
    "# after groupByKey: (ticker: [(1, 0.15), ... , (12, -3.1)])\n",
    "# filters out all the tickers that don't have all 12 months (simpler and more efficient like this)\n",
    "# outputs: (ticker: [list of 12 months with percent_variation])\n",
    "ticker_aggregate_months = ticker_month_variation.map(lambda x: (x[0][0], (x[0][1], x[1]))) \\\n",
    "    .groupByKey() \\\n",
    "    .filter(lambda x: len(x[1]) == 12) \\\n",
    "    .map(lambda x: (x[0], sorted(list(x[1]), key=lambda y: y[0]))) \\\n",
    "    .cache()\n",
    "\n",
    "# Cartesian product to get all possible pairs of ticker\n",
    "# input: (ticker) : ([month_var_list])\n",
    "# after cartesian: ((ticker1) : ([month_var_list1]), (ticker2) : ([month_var_list2]))\n",
    "# Filter to get all pairs of tickers that are similar (percent_var difference per month <= threshold)\n",
    "# the conversion from int month to literal month takes place in merge_months_variations\n",
    "ticker_pairs_threshold = ticker_aggregate_months.cartesian(ticker_aggregate_months) \\\n",
    "    .filter(lambda x: x[0][0] < x[1][0] and compare_months_variations(x[0][1], x[1][1])) \\\n",
    "    .map(lambda x: ((x[0][0], x[1][0]), merge_months_variations(x[0][1], x[1][1])))\n",
    "\n",
    "results = ticker_pairs_threshold.coalesce(1)\n",
    "\n",
    "results.saveAsTextFile(output_filepath)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risultati <a name=\"results\"></a>\n",
    "\n",
    "Di seguito vengono illustrati i risultati ottenuti eseguendo le diverse implementazioni dei job. Inoltre vengono confrontati i tempi di esecuzione al variare delle dimensioni del dataset di input (mostrate nella prima sezione)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job 1 <a name=\"plot1\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "A      1999-11-18    2018-08-24       109.636%    7.510    115.879    \n",
    "AA     1970-01-02    2018-08-24       508.325%    3.604    117.194    \n",
    "AABA   1996-04-12    2018-08-24       4910.909%   0.645    125.031           \n",
    "AAC    2018-01-16    2018-08-24       4.856%      7.789    12.960     \n",
    "AAL    2005-09-27    2018-08-24       101.139%    1.450    63.270    \n",
    "AAME   1980-03-17    2018-08-24      -29.870%     0.375    15.800    \n",
    "AAN    1987-01-20    2018-08-24       4683.263%   0.481    51.529    \n",
    "AAOI   2013-09-26    2018-08-24       330.421%    8.079    103.410    \n",
    "AAON   1992-12-16    2018-08-24       41348.203%  0.089    43.299    \n",
    "AAP    2001-11-29    2018-08-24       1084.149%   12.329   201.240  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job 2 <a name=\"plot2\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "BASIC INDUSTRIES    2009    3.482     GURE    709.722   FCX   9141685400.0\n",
    "BASIC INDUSTRIES    2010    21.790    BLD     519.802   FCX   6891808600.0\n",
    "BASIC INDUSTRIES    2011   -58.600    ROAD    188.704   FCX   5150807800.0\n",
    "BASIC INDUSTRIES    2012   -68.788    PATK    261.860   VALE  4659766700.0\n",
    "BASIC INDUSTRIES    2013    10.322    XRM     416.927   VALE  4428233700.0\n",
    "BASIC INDUSTRIES    2014   -71.902    BLD     884.599   VALE  5660183200.0\n",
    "BASIC INDUSTRIES    2015   -48.101    SUM     35191.629 FCX   7286761300.0\n",
    "BASIC INDUSTRIES    2016    13.829    TECK    451.790   FCX   10464699500.0\n",
    "BASIC INDUSTRIES    2017    15.279    OPNT    310.178   VALE  7023267600.0\n",
    "BASIC INDUSTRIES    2018   -3.079     XRM     213.817   VALE  3710091900.0\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job 3 <a name=\"plot3\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "('OSBCP', 'TCRZ'){\n",
    "'GEN': (1.678, 1.768), 'FEB': (0.389, 0.077), 'MAR': (0.0, 0.735), \n",
    "'APR': (0.875, 1.124), 'MAG': (-0.095, -0.192), 'GIU': (1.156, 0.578), \n",
    "'LUG': (0.190, -0.307), 'AGO': (-0.382, 0.269), 'SET': (-0.286, -0.546), \n",
    "'OTT': (0.673, 0.387), 'NOV': (-0.095, -0.424), 'DIC': (-0.382, -0.276)}\n",
    "\n",
    "('OSBCP', 'ISF'){\n",
    "'GEN': (1.678, 0.832), 'FEB': (0.389, 0.512), 'MAR': (0.0, -0.117), \n",
    "'APR': (0.875, 0.698), 'MAG': (-0.095, -0.885), 'GIU': (1.156, 0.310), \n",
    "'LUG': (0.190, 0.426), 'AGO': (-0.382, -0.385), 'SET': (-0.286, -0.541), \n",
    "'OTT': (0.673, 0.194), 'NOV': (-0.095, -0.233), 'DIC': (-0.382, 0.038)}\n",
    "\n",
    "('OXLCO', 'VRIG'){\n",
    "'GEN': (0.078, 0.247), 'FEB': (0.980, 0.159), 'MAR': (-0.583, 0.0), \n",
    "'APR': (0.352, 0.433), 'MAG': (-0.039, -0.067), 'GIU': (-0.313, -0.118), \n",
    "'LUG': (0.668, -0.079), 'AGO': (-0.078, -0.015), 'SET': (-0.859, 0.075), \n",
    "'OTT': (-0.937, -0.051), 'NOV': (-0.828, -0.019), 'DIC': (0.474, 0.003)}\n",
    "\n",
    "('OXLCO', 'VGSH'){\n",
    "'GEN': (0.078, 0.214), 'FEB': (0.980, 0.049), 'MAR': (-0.583, 0.197), \n",
    "'APR': (0.352, 0.115), 'MAG': (-0.039, 0.164), 'GIU': (-0.313, -0.016), \n",
    "'LUG': (0.668, 0.214), 'AGO': (-0.078, 0.164), 'SET': (-0.859, -0.131), \n",
    "'OTT': (-0.937, -0.098), 'NOV': (-0.828, -0.148), 'DIC': (0.474, -0.198)}\n",
    "\n",
    "('OXLCO', 'VCSH'){\n",
    "'GEN': (0.078, 0.441), 'FEB': (0.980, 0.364), 'MAR': (-0.583, 0.163), \n",
    "'APR': (0.352, 0.288), 'MAG': (-0.039, 0.501), 'GIU': (-0.313, 0.087), \n",
    "'LUG': (0.668, 0.463), 'AGO': (-0.078, 0.261), 'SET': (-0.859, -0.012), \n",
    "'OTT': (-0.937, 0.062), 'NOV': (-0.828, -0.250), 'DIC': (0.474, -0.276)}\n",
    "\n",
    "('OXLCO', 'CIU'){\n",
    "'GEN': (0.078, 0.462), 'FEB': (0.980, 0.775), 'MAR': (-0.583, 0.322), \n",
    "'APR': (0.352, 0.513), 'MAG': (-0.039, 0.704), 'GIU': (-0.313, 0.009), \n",
    "'LUG': (0.668, 0.813), 'AGO': (-0.078, 0.408), 'SET': (-0.859, -0.054), \n",
    "'OTT': (-0.937, 0.018), 'NOV': (-0.828, -0.218), 'DIC': (0.474, -0.128)}\n",
    "\n",
    "('OXLCO', 'ECCB'){\n",
    "'GEN': (0.078, 0.196), 'FEB': (0.980, 0.765), 'MAR': (-0.583, 0.308), \n",
    "'APR': (0.352, 0.193), 'MAG': (-0.039, 0.613), 'GIU': (-0.313, -0.644), \n",
    "'LUG': (0.668, 1.006), 'AGO': (-0.078, 0.723), 'SET': (-0.859, -0.643), \n",
    "'OTT': (-0.937, -0.950), 'NOV': (-0.828, -0.076), 'DIC': (0.474, 0.114)}\n",
    "\n",
    "('OXLCO', 'FTSM'){\n",
    "'GEN': (0.078, 0.033), 'FEB': (0.980, 0.083), 'MAR': (-0.583, -0.016), \n",
    "'APR': (0.352, 0.0), 'MAG': (-0.039, -0.016), 'GIU': (-0.313, 0.008), \n",
    "'LUG': (0.668, 0.016), 'AGO': (-0.078, 0.016), 'SET': (-0.859, 0.0), \n",
    "'OTT': (-0.937, 0.049), 'NOV': (-0.828, -0.016), 'DIC': (0.474, -0.049)}\n",
    "\n",
    "('OXLCO', 'HYLS'){\n",
    "'GEN': (0.078, 0.144), 'FEB': (0.980, 1.049), 'MAR': (-0.583, -0.832), \n",
    "'APR': (0.352, 0.429), 'MAG': (-0.039, 0.386), 'GIU': (-0.313, -0.606), \n",
    "'LUG': (0.668, 0.567), 'AGO': (-0.078, -0.685), 'SET': (-0.859, -0.406), \n",
    "'OTT': (-0.937, -0.346), 'NOV': (-0.828, -0.654), 'DIC': (0.474, 0.020)}\n",
    "\n",
    "('OXLCO', 'HYXE'){\n",
    "'GEN': (0.078, 0.434), 'FEB': (0.980, 1.196), 'MAR': (-0.583, -1.427), \n",
    "'APR': (0.352, 0.868), 'MAG': (-0.039, 0.428), 'GIU': (-0.313, 0.283), \n",
    "'LUG': (0.668, 0.767), 'AGO': (-0.078, -0.319), 'SET': (-0.859, -0.286), \n",
    "'OTT': (-0.937, -0.009), 'NOV': (-0.828, -0.440), 'DIC': (0.474, -0.351)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusioni <a name=\"conclusions\"></a>\n",
    "The first paragraph text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
